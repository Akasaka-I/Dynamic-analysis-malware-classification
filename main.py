import dataProcessing as dp
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from torchvision import transforms
from sklearn.preprocessing import LabelEncoder
import torch.utils.data as data
import torch.nn.functional as F
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import pandas as pd
from PIL import Image
import seaborn as sns

batchSize = 16
epochs = 20  # Increased epochs

class MalwareCNN(nn.Module):
    def __init__(self, num_classes):
        super(MalwareCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(32 * 56 * 56, 128)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 32 * 56 * 56)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Check if CUDA is available and set the device accordingly
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Load data
img, label, classNum = dp.readData()

# Encode labels
labelEncoder = LabelEncoder()
label = labelEncoder.fit_transform(label)

# Data augmentation
transform = transforms.Compose([
    #transforms.Grayscale(num_output_channels=1),  # Convert to grayscale
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

# Apply transformation
img_list = []
for i in range(len(img)):
    pil_img = Image.fromarray(img[i].astype('uint8'))
    transformed_img = transform(pil_img)
    img_list.append(transformed_img)

# Stack transformed images
img = torch.stack(img_list)

label = torch.tensor(label, dtype=torch.long)

# Create dataset
dataSet = TensorDataset(img, label)
trainSize = int(0.8 * len(dataSet))
testSize = len(dataSet) - trainSize
trainDataSet, testDataSet = data.random_split(dataSet, [trainSize, testSize])

# Create data loaders
train_loader = DataLoader(trainDataSet, batch_size=batchSize, shuffle=True)
test_loader = DataLoader(testDataSet, batch_size=batchSize, shuffle=False)

# Initialize model
model = MalwareCNN(num_classes=classNum)
model.to(device)  # Move model to the device
criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Learning rate scheduler

# Train model
for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    y_true = []
    y_pred = []
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the device
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)  # Remove l2_loss as it is not defined
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

    avg_loss = running_loss / len(train_loader)
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)
    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)
    f1 = f1_score(y_true, y_pred, average='macro')

    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')

    # Step the scheduler
    scheduler.step()

# Test model
model.eval()
with torch.no_grad():
    y_true = []
    y_pred = []
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the device
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)
    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)
    f1 = f1_score(y_true, y_pred, average='macro')

    print(f'Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')

    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    labels = labelEncoder.inverse_transform(range(classNum))
    df_cm = pd.DataFrame(cm, index=labels, columns=labels)
    plt.figure(figsize=(10, 8))
    sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted', rotation=0)
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()
    plt.savefig('confusion_matrix.png')
    